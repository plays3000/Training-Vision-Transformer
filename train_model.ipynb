{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from cropping_dataset import CustomImageDataset, DPImageDataset\n",
    "from build_network import *\n",
    "from sklearn.metrics import classification_report, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import engine\n",
    "import warnings\n",
    "import timm\n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/storage2/hyunjoong/cancer/DINO_knn')\n",
    "import vision_transformer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12345'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0,2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2\"\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    \"\"\"Linear layer to train on top of frozen features\"\"\"\n",
    "    def __init__(self, dim, num_labels=1000):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.linear1 = nn.Linear(dim, 2048, bias = True)\n",
    "        self.dropout1 = nn.Dropout(p = 0.4)\n",
    "        self.act1 = nn.GELU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(2048, 256, bias = True)\n",
    "        self.dropout2 = nn.Dropout(p = 0.4)\n",
    "        self.act2 = nn.GELU()\n",
    "        \n",
    "        # self.linear3 = nn.Linear(2048, 256, bias = True)\n",
    "        # self.dropout3 = nn.Dropout(p = 0.4)\n",
    "        # self.act3 = nn.GELU()\n",
    "        \n",
    "        self.out = nn.Linear(256, num_labels, bias = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        # x = self.linear3(x)\n",
    "        # x = self.dropout3(x)\n",
    "        # x = self.act3(x)\n",
    "\n",
    "        # linear layer\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_model(nn.Module):\n",
    "    def __init__(self, vit):\n",
    "        super().__init__()\n",
    "        self.vit = vit\n",
    "        # for param in self.vit.parameters():\n",
    "        #     param.required_grad = False\n",
    "        self.classifier = nn.Linear(768, 2, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.vit(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custem Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./best_model.pth')\n",
    "model.load_state_dict(torch.load('./checkpoint.pth')['student'], strict = False)\n",
    "model = model.module.backbone\n",
    "embed_dim = model.embed_dim\n",
    "model.head = nn.Linear(embed_dim, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 5\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    # dataset_val = datasets.ImageFolder(os.path.join(args.data_path, \"val\"), transform=val_transform)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomApply([transforms.ColorJitter(brightness = 0.4, contrast = 0.4, saturation = 0.2, hue = 0.1)],\n",
    "                                   p = 0.8),\n",
    "            transforms.RandomGrayscale(p = 0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "    # dataset_train = datasets.ImageFolder(os.path.join(args.data_path, \"train\"), transform=train_transform)\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_val = DPImageDataset('../val3_df.csv', transform = val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        dataset_val,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle = True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "dataset_train = DPImageDataset('../train3_df.csv', transform = train_transform)\n",
    "    # dist.init_process_group(backend='nccl', init_method='env://')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle = True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "test_dataset = DPImageDataset('../test3_df.csv', transform = test_transform)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             num_workers=num_workers,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trainig the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 100\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr = lr, # linear scaling rule\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=0, # we do not apply weight decay\n",
    "                            )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = optimizer, mode = 'min', patience = 3, min_lr=1e-8)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model, hist = engine.train(model = model, \n",
    "                           train_dataloader = train_loader, \n",
    "                           test_dataloader = val_loader, \n",
    "                           optimizer = optimizer,\n",
    "                           scheduler = scheduler,\n",
    "                           loss_fn =  loss_fn,\n",
    "                           epochs = epochs,\n",
    "                           output_dir = './classifier_checkpoint',\n",
    "                           device = device,\n",
    "                           parallel = True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './vitb8_dataset2048/vitb8_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VisionTransformer import vision_transformer\n",
    "model= torch.load('./vits16_data2048/checkpoint_model.pt')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_acc = 0\n",
    "test_loss = 0\n",
    "preds = []\n",
    "y_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data,target in tqdm(test_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        y_label = list(target.detach().cpu().numpy())\n",
    "        y_labels.append(y_label)\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        # test_pred_labels = output.argmax(dim=1)\n",
    "        \n",
    "        \n",
    "        y_pred_class = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "        pred = list(y_pred_class.detach().cpu().numpy())\n",
    "        preds.append(pred)\n",
    "        test_acc += ((y_pred_class == target).sum().item()/len(y_pred_class))\n",
    "\n",
    "preds = list(itertools.chain(*preds))\n",
    "y_labels = list(itertools.chain(*y_labels))\n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_acc = test_acc / len(test_dataloader)\n",
    "print(f'test_loss : {test_loss} | test_acc : {test_acc}')\n",
    "\n",
    "report = classification_report(preds, y_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "print(f\"precision : {precision_score(preds, y_labels)}\")\n",
    "print(f\"recall : {recall_score(preds, y_labels)}\")\n",
    "print(f\"f1_score : {f1_score(preds, y_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyunjoong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
